## Ideas for LLM Response Validation

- There will be a UI, which would take in two parameters initially, there will be a base system prompt and the user has to enter the domain in which they are interested in, Ex: (Math/Games/Sports).
- The LLM would take in these two parameters, and based on that the LLM would be able to answer the questions the user asks.
- For each response generated by the LLM, there will be multiple fields:</br>
    a) Rating System between (1-5) Where value towards 1 tends to a bad response and value towards 5 tends to a good response.</br>
    b) There will also be a textbox, where the user can give feedback to the generated response.</br>
    c) Based on the feedback, received from the user the LLM will auto finetune the system prompt based on the user feedback.
- There will be a second LLM that would take the decision on whether it wants to finetune the prompt based on the user feedback.
- The second LLM would receive the original system prompt, user feedback and rating as inputs.
- This can be thought of Prompt finetuning mechanism as opposed to LLM Response finetuning.
- If there are any tool calls, the LLM response can be evaluated after the tool call.

## Prompt Calibration Ideas

- This can be thought of a way to optimize prompts for open source models.
- We can have a base prompt and response coming from an x-model (Ex: Gemma 3, Mistral)
- Their response would go through a human validation/feedback which would consist of rating on a numerical scale along with natural language feedback.
- This can be fed as input to proprietary model y-model (Ex: GPT-4o, Gemini) superior to the open source model which would calibrate the prompt.

### Endpoints Needed:

- `/chat` => This is the chat interface, which is a streaming API.
- `/chat/feedback` => This endpoint can give the feedback to y-model to calibrate (Two buttons would be present which says calibrate or continue)

### Tables Needed:
- `User` => Table to maintain Users
- `Session` => Table to maintain chat sessions
- `Chat` => This table will store all the messages from the user.
- `Prompt` => This table will store all the prompts
- `PromptVersion` => This table will store all the calibrated prompts from the base version

## Table Structure:

User: id, name, email, password
Session: id, user_id , session_name
Chat: id, session_id, role, content , model_used , prompt_version_id , rating, feedback_text, action, created_at
Prompt: id, name, base_prompt, current_version_id
PromptVersion: id, prompt_id, version_number, calibrated_prompt, created_at